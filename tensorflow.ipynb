{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit ('3.8')"
  },
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TensorFlow Core Learning Algorithms\n",
    "- Linear Regression\n",
    "- Classification\n",
    "- Clustering\n",
    "- Hidden Markov Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Linear Regression:\n",
    "- One of the most basic forms of machine learning\n",
    "- Predicts numberic values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.3 is available.\nYou should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x # only required in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "source": [
    "## Load dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv('./data/train.csv')\n",
    "dfeval = pd.read_csv('./data/eval.csv')\n",
    "\n",
    "y_train = dftrain.pop('survived') # pops the 'survived' column from dftrain dataframe\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "source": [
    "# Training and testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']\n",
    "\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique() # gets all the unqiue values\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
   ]
  },
  {
   "source": [
    "## Training process\n",
    "### Epoch:\n",
    "- A single stream of entire dataset\n",
    "- refers to the number of times the training model will see the entire dataset\n",
    "### Batches:\n",
    "- Model receives the data in batches\n",
    "### Batch size:\n",
    "- refers to the number of rows fed to the model at a time\n",
    "### Input Function:\n",
    "- defines how the data will be broken into epochs and batches before being fed to the training model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## input function:\n",
    "- encodes the data into a **tf.data.Dataset** object"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function(): # Inner function, this will be returned\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df)) # create tf.data.Dataset object with data and its labels\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000) # randomize order of data\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs) # splits dataset into 32 batches and repeats process for number of epochs\n",
    "        return ds # return a batch of the dataset\n",
    "    return input_function # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n"
   ]
  },
  {
   "source": [
    "## Creating a model\n",
    "- create linear estimaor from feature_columns created before"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/px/lrt6ypmn0rq6y7tspwnw2ybh0000gn/T/tmpqp4s0e9m\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/px/lrt6ypmn0rq6y7tspwnw2ybh0000gn/T/tmpqp4s0e9m', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
   ]
  },
  {
   "source": [
    "## Training the model\n",
    "- pass in the training input function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.74242425\n"
     ]
    }
   ],
   "source": [
    "linear_est.train(train_input_fn) # Train\n",
    "result = linear_est.evaluate(eval_input_fn) # get model metrics/stats by testing on test data\n",
    "\n",
    "clear_output() # clears console output\n",
    "print(result['accuracy'])"
   ]
  },
  {
   "source": [
    "## Predictions\n",
    "- making predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sex                          male\nage                          35.0\nn_siblings_spouses              0\nparch                           0\nfare                         8.05\nclass                       Third\ndeck                      unknown\nembark_town           Southampton\nalone                           y\nName: 0, dtype: object\n0\nchance of survivial:  0.15846267\nchance of non-survivial:  0.8415373\n"
     ]
    }
   ],
   "source": [
    "result = list(linear_est.predict(eval_input_fn))\n",
    "clear_output()\n",
    "print(dfeval.loc[0])\n",
    "print(y_eval.loc[0])\n",
    "print('chance of survivial: ', result[0]['probabilities'][1])\n",
    "print('chance of non-survivial: ', result[0]['probabilities'][0])"
   ]
  },
  {
   "source": [
    "# Classification:\n",
    "- Predicts class\n",
    "- Seperates data points into different classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
    "# https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
    "\n",
    "train = pd.read_csv('./data/iris_training.csv', names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv('./data/iris_test.csv', names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLength</th>\n      <th>SepalWidth</th>\n      <th>PetalLength</th>\n      <th>PetalWidth</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.4</td>\n      <td>2.8</td>\n      <td>5.6</td>\n      <td>2.2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>2.3</td>\n      <td>3.3</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.9</td>\n      <td>2.5</td>\n      <td>4.5</td>\n      <td>1.7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.7</td>\n      <td>3.8</td>\n      <td>1.7</td>\n      <td>0.3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')"
   ]
  },
  {
   "source": [
    "## Input function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    \n",
    "    # Shuffle and repeat if in training mode\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "source": [
    "## Feature columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "my_features_columns = []\n",
    "for key in train.keys():\n",
    "    my_features_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_features_columns)"
   ]
  },
  {
   "source": [
    "# Building the model\n",
    "choices include:\n",
    "- DNNSClassifier (Deep Neural Network)\n",
    "- LinearClassifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/px/lrt6ypmn0rq6y7tspwnw2ybh0000gn/T/tmpyjdxgxba\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/px/lrt6ypmn0rq6y7tspwnw2ybh0000gn/T/tmpyjdxgxba', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_features_columns,\n",
    "    # Two hidden layes of 30 and 10 nodes\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes\n",
    "    n_classes=3\n",
    ")"
   ]
  },
  {
   "source": [
    "# Training:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/px/lrt6ypmn0rq6y7tspwnw2ybh0000gn/T/tmpyjdxgxba/model.ckpt-5000\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/saver.py:1078: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/px/lrt6ypmn0rq6y7tspwnw2ybh0000gn/T/tmpyjdxgxba/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:loss = 0.79971766, step = 5000\n",
      "INFO:tensorflow:global_step/sec: 121.755\n",
      "INFO:tensorflow:loss = 0.7966646, step = 5100 (0.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.045\n",
      "INFO:tensorflow:loss = 0.79523456, step = 5200 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.964\n",
      "INFO:tensorflow:loss = 0.79899925, step = 5300 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.374\n",
      "INFO:tensorflow:loss = 0.7962625, step = 5400 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.088\n",
      "INFO:tensorflow:loss = 0.79795635, step = 5500 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.601\n",
      "INFO:tensorflow:loss = 0.79289097, step = 5600 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.775\n",
      "INFO:tensorflow:loss = 0.7892151, step = 5700 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.941\n",
      "INFO:tensorflow:loss = 0.8017322, step = 5800 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.003\n",
      "INFO:tensorflow:loss = 0.79139173, step = 5900 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.587\n",
      "INFO:tensorflow:loss = 0.7933276, step = 6000 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.34\n",
      "INFO:tensorflow:loss = 0.78513587, step = 6100 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.618\n",
      "INFO:tensorflow:loss = 0.7836095, step = 6200 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.165\n",
      "INFO:tensorflow:loss = 0.7819519, step = 6300 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.584\n",
      "INFO:tensorflow:loss = 0.79106754, step = 6400 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.059\n",
      "INFO:tensorflow:loss = 0.78670526, step = 6500 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.913\n",
      "INFO:tensorflow:loss = 0.78481877, step = 6600 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.651\n",
      "INFO:tensorflow:loss = 0.785571, step = 6700 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.697\n",
      "INFO:tensorflow:loss = 0.7823063, step = 6800 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.223\n",
      "INFO:tensorflow:loss = 0.7705874, step = 6900 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.925\n",
      "INFO:tensorflow:loss = 0.769426, step = 7000 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.76\n",
      "INFO:tensorflow:loss = 0.7807185, step = 7100 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.237\n",
      "INFO:tensorflow:loss = 0.7693105, step = 7200 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.738\n",
      "INFO:tensorflow:loss = 0.77150345, step = 7300 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.307\n",
      "INFO:tensorflow:loss = 0.7740692, step = 7400 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.493\n",
      "INFO:tensorflow:loss = 0.7816483, step = 7500 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.509\n",
      "INFO:tensorflow:loss = 0.77400255, step = 7600 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.558\n",
      "INFO:tensorflow:loss = 0.76515543, step = 7700 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.141\n",
      "INFO:tensorflow:loss = 0.7680296, step = 7800 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.214\n",
      "INFO:tensorflow:loss = 0.7724491, step = 7900 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.697\n",
      "INFO:tensorflow:loss = 0.7720537, step = 8000 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.736\n",
      "INFO:tensorflow:loss = 0.7838223, step = 8100 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.286\n",
      "INFO:tensorflow:loss = 0.76190174, step = 8200 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.419\n",
      "INFO:tensorflow:loss = 0.76328665, step = 8300 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.903\n",
      "INFO:tensorflow:loss = 0.7613478, step = 8400 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.322\n",
      "INFO:tensorflow:loss = 0.757014, step = 8500 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.265\n",
      "INFO:tensorflow:loss = 0.7597323, step = 8600 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.305\n",
      "INFO:tensorflow:loss = 0.7811008, step = 8700 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.35\n",
      "INFO:tensorflow:loss = 0.75572205, step = 8800 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.8\n",
      "INFO:tensorflow:loss = 0.76016307, step = 8900 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.573\n",
      "INFO:tensorflow:loss = 0.7581805, step = 9000 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.135\n",
      "INFO:tensorflow:loss = 0.7622071, step = 9100 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.519\n",
      "INFO:tensorflow:loss = 0.75620985, step = 9200 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.676\n",
      "INFO:tensorflow:loss = 0.7511666, step = 9300 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.469\n",
      "INFO:tensorflow:loss = 0.74789584, step = 9400 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.403\n",
      "INFO:tensorflow:loss = 0.75772464, step = 9500 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.562\n",
      "INFO:tensorflow:loss = 0.74372244, step = 9600 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.149\n",
      "INFO:tensorflow:loss = 0.73958826, step = 9700 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.601\n",
      "INFO:tensorflow:loss = 0.75318635, step = 9800 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.176\n",
      "INFO:tensorflow:loss = 0.7628623, step = 9900 (0.448 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/px/lrt6ypmn0rq6y7tspwnw2ybh0000gn/T/tmpyjdxgxba/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
      "INFO:tensorflow:Loss for final step: 0.742987.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x15be67610>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True), \n",
    "    steps=5000)"
   ]
  },
  {
   "source": [
    "# Test trained Model's accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-07-05T12:59:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/px/lrt6ypmn0rq6y7tspwnw2ybh0000gn/T/tmpyjdxgxba/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.64546s\n",
      "INFO:tensorflow:Finished evaluation at 2021-07-05-12:59:17\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.53333336, average_loss = 0.79932284, global_step = 10000, loss = 0.79932284\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /var/folders/px/lrt6ypmn0rq6y7tspwnw2ybh0000gn/T/tmpyjdxgxba/model.ckpt-10000\n",
      "\n",
      "Test set accuracy: 0.533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(lambda: input_fn(test, test_y, training=False ))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "source": [
    "# Clustering:\n",
    "- Finds clusters in datasets\n",
    "- Classifies each data point by finding the closest data clusters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Hidden Markov Model:\n",
    "(Probability Distributions)\n",
    "- Uses probability distribution to make predict future events or states\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}